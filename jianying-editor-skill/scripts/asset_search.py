import os
import csv
import argparse
import sys

# è®¾ç½®åŸºç¡€ç›®å½•
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(BASE_DIR, "data")

# --- æ‰©å±•: å¸¸è§åŒä¹‰è¯æ˜ å°„åº“ ---
# ç”¨äºåå‘æ¨å¯¼ Enum Key
EFFECT_SYNONYMS = {
    "typewriter": ["æ‰“å­—æœº", "å­—å¹•", "typing", "å¤å¤æ‰“å­—æœº"],
    "fade": ["æ¸éš", "æ¸æ˜¾", "é»‘åœº", "ç™½åœº", "fade_in", "fade_out"],
    "glitch": ["æ•…éšœ", "å¹²æ‰°", "ç‡¥æ³¢", "é›ªèŠ±"],
    "zoom": ["æ‹‰è¿‘", "æ‹‰è¿œ", "ç¼©æ”¾", "å˜ç„¦"],
    "shake": ["æŒ¯åŠ¨", "æ‘‡æ™ƒ", "æŠ–åŠ¨"],
    "blur": ["æ¨¡ç³Š", "è™šåŒ–"],
    "glow": ["å‘å…‰", "è¾‰å…‰", "éœ“è™¹"],
    "retro": ["å¤å¤", "èƒ¶ç‰‡", "æ€€æ—§", "DV"],
    "dissolve": ["å åŒ–", "æº¶è§£", "æ··åˆ"],
}

SYNONYMS = {
    # å¸¸ç”¨è‹±æ–‡ -> ä¸­æ–‡
    "dissolve": ["å åŒ–", "æº¶è§£", "æ··åˆ"],
    "fade": ["æ¸éš", "æ¸æ˜¾", "é»‘åœº", "ç™½åœº"],
    "glitch": ["æ•…éšœ", "å¹²æ‰°", "ç‡¥æ³¢", "é›ªèŠ±"],
    "zoom": ["æ‹‰è¿‘", "æ‹‰è¿œ", "ç¼©æ”¾", "å˜ç„¦"],
    "shake": ["æŒ¯åŠ¨", "æ‘‡æ™ƒ", "æŠ–åŠ¨"],
    "blur": ["æ¨¡ç³Š", "è™šåŒ–"],
    "glow": ["å‘å…‰", "è¾‰å…‰", "éœ“è™¹"],
    "retro": ["å¤å¤", "èƒ¶ç‰‡", "æ€€æ—§", "DV"],
    "film": ["èƒ¶ç‰‡", "ç”µå½±", "é¢—ç²’"],
    "typewriter": ["æ‰“å­—æœº", "å­—å¹•"],
    "particle": ["ç²’å­", "ç¢ç‰‡"],
    "fire": ["ç«", "ç‡ƒçƒ§", "çƒˆç„°"],
    "rain": ["é›¨", "æ°´æ»´"],
    "cyber": ["èµ›åš", "ç§‘æŠ€", "æ•°ç "],
    "scan": ["æ‰«æ", "å…¨æ¯"],
    
    # åœºæ™¯åŒ–æè¿°
    "tech": ["ç§‘æŠ€", "å…¨æ¯", "æ‰«æ", "æ•°æ®"],
    "memory": ["å›å¿†", "é»‘ç™½", "æ³›é»„", "æŸ”å…‰"],
    "horror": ["ææ€–", "æƒŠæ‚š", "æš—é»‘", "è¡€"],
    "happy": ["æ¬¢ä¹", "è·³åŠ¨", "å¼¹åŠ›"],
}

def expand_query_with_synonyms(query):
    """æ‰©å±•æŸ¥è¯¢è¯"""
    terms = query.lower().split()
    expanded_terms = set(terms)
    for term in terms:
        if term in SYNONYMS:
            expanded_terms.update(SYNONYMS[term])
        else:
            for key, values in SYNONYMS.items():
                if term in key:
                    expanded_terms.update(values)
    return list(expanded_terms)

def get_enum_key_from_ident(ident):
    """å°è¯•ä»ä¸­æ–‡æ ‡è¯†ç¬¦åæ¨è‹±æ–‡ Enum Key"""
    ident_lower = ident.lower()
    for key, synonyms in EFFECT_SYNONYMS.items():
        if key in ident_lower: return key
        for syn in synonyms:
            if syn in ident_lower:
                return key
    return ""

def search_assets(query, category=None, limit=20):
    """æœç´¢èµ„äº§"""
    results = []
    search_terms = expand_query_with_synonyms(query)
    
    files_to_search = []
    if category:
        if not category.endswith('.csv'): category += '.csv'
        files_to_search = [category]
    else:
        if os.path.exists(DATA_DIR):
            files_to_search = [f for f in os.listdir(DATA_DIR) if f.endswith('.csv')]
        else:
            print(f"âŒ Error: Data directory not found at {DATA_DIR}")
            return []

    for filename in files_to_search:
        filepath = os.path.join(DATA_DIR, filename)
        if not os.path.exists(filepath): continue
            
        with open(filepath, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                target_text = (row.get('identifier', '') + " " + 
                               row.get('description', '') + " " + 
                               row.get('category', '')).lower()
                
                score = 0
                if query.lower() in target_text: score += 100
                for term in search_terms:
                    if term in target_text: score += 10
                
                if score > 0:
                    row['score'] = score
                    row['source_file'] = filename
                    results.append(row)

    results.sort(key=lambda x: x['score'], reverse=True)
    return results[:limit]

def format_results(results):
    if not results:
        return "âŒ æœªæ‰¾åˆ°åŒ¹é…é¡¹ã€‚å°è¯•ä½¿ç”¨æ›´ç®€å•çš„ä¸­æ–‡å…³é”®è¯ã€‚"
    
    output = []
    # æ˜ç¡®å‘Šè¯‰ Agent: è¿™äº›ä¸­æ–‡åå°±æ˜¯å¯ä»¥ç›´æ¥ç”¨çš„ ID
    header = f"{'Identifier':<25} | {'Category':<15} | {'API Key (Use This)':<20} | {'Source'}"
    output.append(header)
    output.append("-" * len(header))
    
    for r in results:
        ident = r.get('identifier', 'N/A')
        display_ident = ident
        if len(display_ident) > 23: display_ident = display_ident[:20] + "..."
        
        cat = r.get('category', 'N/A')[:15]
        src = r.get('source_file', '').replace('.csv', '')
        
        enum_key = get_enum_key_from_ident(ident)
        if not enum_key:
            enum_key = ident  # Fallback to Chinese Key
        
        if len(enum_key) > 18: enum_key = enum_key[:15] + "..."

        output.append(f"{display_ident:<25} | {cat:<15} | {enum_key:<20} | {src}")
        
    return "\n".join(output)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="å‰ªæ˜ èµ„äº§æœç´¢å·¥å…· (æ™ºèƒ½åŒè¯­ç‰ˆ)")
    parser.add_argument("query", nargs="?", default=None, help="æœç´¢å…³é”®è¯")
    parser.add_argument("-c", "--category", help="é™å®šåˆ†ç±»")
    parser.add_argument("-l", "--limit", type=int, default=20, help="æ•°é‡é™åˆ¶")
    parser.add_argument("--list", action="store_true", help="åˆ—å‡ºåˆ†ç±»")
    
    args = parser.parse_args()
    
    if args.list:
        print("=== å‰ªæ˜ èµ„äº§æ•°æ®åº“æ¦‚è§ˆ ===")
        if os.path.exists(DATA_DIR):
            for filename in sorted(os.listdir(DATA_DIR)):
                if filename.endswith('.csv'):
                    with open(os.path.join(DATA_DIR, filename), 'r', encoding='utf-8') as f:
                        print(f"{filename:<30} | {sum(1 for line in f) - 1}")
        sys.exit(0)

    if not args.query:
        parser.print_help()
        sys.exit(0)

    print(f"ğŸ” Searching for '{args.query}' (Smart Synonyms Enabled)...")
    search_results = search_assets(args.query, args.category, args.limit)
    print(format_results(search_results))
